{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd2981d",
   "metadata": {},
   "source": [
    "Goal: test early text extraction logic for TXT, DOCX, and PDF inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d45f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_text_reading():\n",
    "    file_path = r'/home/rohanseq48/Git_projects/rag-chatbot-docsearch/notebooks/Text_file.txt'\n",
    "\n",
    "    try:\n",
    "        with open(file, 'r', encoding= 'utf-8') as file:\n",
    "            lines = file.read().splitlines()\n",
    "            print(f\"Read {len(lines)} lines\" )\n",
    "            print(lines)\n",
    "            return lines\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")  \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e43b6418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file: local variable 'file' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "test_text_reading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1 : discovery\n",
    "\n",
    "def discover(input_path_or_filelike):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    - Accept a single path, list of paths, glob, or an upload/file-like object from API.\n",
    "    - Yield a canonical file descriptor for each candidate file that downstream handlers can use.\n",
    "\n",
    "    FileDescriptor contract (what this function should yield):\n",
    "    {\n",
    "      'source': original input (Path or identifier),\n",
    "      'path': filesystem Path if available (may be a temp file for uploads),\n",
    "      'file_like': optional file-like object (seekable preferred) if not written to disk,\n",
    "      'ext': lower-case extension if present,\n",
    "      'mime': optional sniffed mime type,\n",
    "      'size': file size in bytes (if known),\n",
    "      'mtime': modification time (if available),\n",
    "      'quick_hash': fast partial hash for dedup decisions,\n",
    "      'suggested_handler': one of ['txt', 'pdf', 'docx', 'image', 'archive', 'binary'] OR None,\n",
    "      'notes': list of diagnostic strings (e.g., 'uploaded', 'temp_written', 'non_utf_bytes')\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: normalise input form\n",
    "    # - If input is a single Path string: convert to Path and handle\n",
    "    # - If input is a list: iterate each element and handle\n",
    "    # - If input is a glob pattern: expand to matching paths (honour recursive flag)\n",
    "    # - If input is an UploadFile / file-like: mark as upload and go to upload handling branch\n",
    "\n",
    "    # TODO: if input is a dir: walk directory (honour recursive & ignore patterns) and yield files\n",
    "\n",
    "    # TODO: for each candidate file:\n",
    "    #   - gather stat info: size, mtime when available\n",
    "    #   - determine extension from filename (lower-case)\n",
    "    #   - attempt magic sniff: read first 4-512 bytes in binary mode and run mime/type detection\n",
    "    #   - compute quick_hash: e.g., sha256(first N bytes + size + mtime) for lightweight dedup checking\n",
    "    #   - pick suggested_handler using:\n",
    "    #       * extension mapping (fast)\n",
    "    #       * mime sniff fallback\n",
    "    #       * if ext ambiguous or missing, mark as 'binary' for further inspection\n",
    "    #   - if file is an upload (file-like) and handler requires path:\n",
    "    #       * write to a temp file in cache_dir and note 'temp_written' in notes\n",
    "    #   - compute 'utf_likely' heuristic:\n",
    "    #       * open first chunk in binary; if lots of NUL bytes -> binary not text\n",
    "    #       * otherwise try to decode with UTF-8; if success, mark utf_likely True, else set False\n",
    "    #   - yield FileDescriptor dictionary as defined above\n",
    "\n",
    "    # TODO: ensure robust error handling\n",
    "    # - For permission/IO errors, log and yield a descriptor with 'error' in notes\n",
    "    # - For unreadable paths, skip but record reason\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Step 2 : File Routing\n",
    "#once file is read we can put it in a database table called raw\n",
    "\n",
    "\n",
    "### Step 3 : Extraction\n",
    "### Step 4 : Yield documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
