# ğŸ§  rag-chatbot-docsearch

An AI-powered document retrieval and question-answering system built with FastAPI, LlamaIndex, and ChromaDB.

---

## ğŸš€ Overview
rag-chatbot-docsearch ingests documents (e.g., PDFs, text files), converts them into embeddings, and allows natural-language querying using a retrieval-augmented generation (RAG) pipeline.

---

## ğŸ§© Architecture

**Modules**
- `data_ingestion/` â†’ load & chunk documents  
- `embeddings/` â†’ generate and store embeddings  
- `retrieval/` â†’ search vector DB  
- `api/` â†’ expose endpoints for query and ingestion  

---

## âš™ï¸ Tech Stack
- **Backend:** FastAPI  
- **LLM/RAG:** LlamaIndex, OpenAI API  
- **Vector Store:** ChromaDB  
- **Environment:** Python 3.10+  
- **Deployment:** Docker + Render (planned)

---

## ğŸ§­ Setup Instructions
```bash
git clone git@github.com:rzseq48/rag-chatbot-docsearch.git
cd rag-chatbot-docsearch
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

Set up your environment variables in .env:
OPENAI_API_KEY=your_key

Run the FastAPI app:
uvicorn app.main:app --reload
